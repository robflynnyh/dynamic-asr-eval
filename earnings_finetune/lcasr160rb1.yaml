model:
  feat_in: 80
  n_layers: 6
  d_model: 768
  n_heads: 6
  head_dim: 128
  dropout_ff: 0.0
  dropout_attn: 0.0
  dropout_conv: 0.0
  subsampling_factor: 8
  subsampling: dw_striding
  subsampling_act: silu
  subsampling_conv_channels: 256
  self_condition_subsampling: false
  subsampling_norm_out: false
  conv_kernel_size: 9
  qk_rms_norm: false
  shift_kvs: false
  self_conditioning: true
  gated_sc: false
  decoder_norm: true
  use_rotary: true
  encoder_mode: conformer
  default_norm: layer_norm
  sandwich_norm: false
  bias_in_ff: false
  checkpoint_every_n_layers: 0
  rotary_base_freq: 1500000
  flash_attn: false # doesnt work with head size 128 on A4500s!

optimizer:
  name: madgrad
  args:
    lr: 1e-6

scheduler:
  warmup_steps: 1

audio_chunking:
  size: 16384
  overlap: 0

wandb:
  use: true
  project_name: earnings22_NST_finetune
  name: rb_n_seq_sched_16384_rp_1
  id: ""

checkpointing:
  dir: /exp/exp4/acp21rjf/checkpoints/earnings22NSTfinetune/
  
data:
  path: /store/store4/data/earnings-22/earnings_train.json

training:
  ema_decay: 0.9999
  batch_size: 4
  backprop_every: 1
  backwards_every: 1
  max_seq_len: 0
  clip_value: 0.8
  intermediate_loss_weighting: 0.0
  random_seed: 8241
  max_epochs: 5


description: NST finetuning on earnings22 


model_class: SCConformerXL

spec_augment:
  n_time_masks: 0
  time_mask_param: 0
  n_freq_masks: 6
  freq_mask_param: 34
  iid_masks: true
  min_p: 0.0
  max_p: 0.0
  zero_masking: false
